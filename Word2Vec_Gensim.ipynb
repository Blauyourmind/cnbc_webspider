{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = [word for word in set(stopwords.words('english'))] # get stopwords from nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s, lower=True, strip_punc=True):\n",
    "    '''\n",
    "    Input: String, lower(Bool), strip_punc(Bool)\n",
    "    Output: List of Strings\n",
    "    '''\n",
    "    punc = '.-,?<>:;\"\\'!%'\n",
    "    if isinstance(s, str):\n",
    "        s = s.split() # tokenize text\n",
    "    if lower:\n",
    "        s = [t.lower() for t in s]\n",
    "    if strip_punc:\n",
    "        s = [t.strip(punc) for t in s]\n",
    "        \n",
    "    return s\n",
    "\n",
    "def token_frequency(tokens, tf= None, relative=False):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "        tokens = List of Strings or None\n",
    "        tf = dict or None\n",
    "        relative = Boolean\n",
    "    Output: \n",
    "        Dictionary of a token frequencies\n",
    "    \"\"\"\n",
    "    tf = {} if tf==None else tf\n",
    "    \n",
    "    if len(tf) != 0 and relative==True:\n",
    "        if isinstance(list(tf.items())[0][1], float):\n",
    "            print('WARNING: Adding raw counts to relative frequency')\n",
    "            return tf\n",
    "        \n",
    "    for token in tokens:\n",
    "        if token in tf:\n",
    "            tf[token] += 1\n",
    "        else:\n",
    "            tf[token] = 1\n",
    "    \n",
    "    if relative:\n",
    "        total = sum([v for k,v in tf.items()])\n",
    "        tf = {k:v/total for k, v in tf.items()}\n",
    "          \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Tokenize New Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53377</th>\n",
       "      <td>2020-12-28 00:00:00+00:00</td>\n",
       "      <td>[japan's, nikkei, 225, surges, to, levels, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53378</th>\n",
       "      <td>2020-12-28 00:00:00+00:00</td>\n",
       "      <td>[u.s, might, be, missing, the, new, covid, var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53496</th>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>[dow, futures, indicate, 200-point, gain, as, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53501</th>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>[dow, jumps, 300, points, to, record, high, as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53504</th>\n",
       "      <td>2020-12-27 00:00:00+00:00</td>\n",
       "      <td>[alibaba, shares, plunge, about, 8, for, secon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   publish_date  \\\n",
       "53377 2020-12-28 00:00:00+00:00   \n",
       "53378 2020-12-28 00:00:00+00:00   \n",
       "53496 2020-12-27 00:00:00+00:00   \n",
       "53501 2020-12-27 00:00:00+00:00   \n",
       "53504 2020-12-27 00:00:00+00:00   \n",
       "\n",
       "                                                headline  \n",
       "53377  [japan's, nikkei, 225, surges, to, levels, not...  \n",
       "53378  [u.s, might, be, missing, the, new, covid, var...  \n",
       "53496  [dow, futures, indicate, 200-point, gain, as, ...  \n",
       "53501  [dow, jumps, 300, points, to, record, high, as...  \n",
       "53504  [alibaba, shares, plunge, about, 8, for, secon...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in cnbc articles\n",
    "df = pd.read_csv('data/cnbc_news.csv', parse_dates=['publish_date'])\n",
    "df['publish_date'] = df['publish_date'].dt.tz_convert('UTC')\n",
    "\n",
    "# drop any rows with null\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# preprocess text in headlines\n",
    "df['headline'] = df['headline'].apply(lambda x: preprocess(x))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec With Gensim\n",
    "\n",
    "Resources: \n",
    "- https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['lobbyist', 'brother', 'of', 'biden', 'advisor', 'has', 'reputation', 'for', 'deep', 'connections', 'and', 'looking', 'to', 'avoid', 'possible', 'conflicts']),\n",
       "       list(['how', 'to', 'navigate', 'the', 'world', 'of', 'sustainable', 'investing', 'ratings'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gensim takes a list of lists input: a list of tokenized documents\n",
    "# here, we will treat news headlines as documents\n",
    "docs = df['headline'].values\n",
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word2vec model with gensim\n",
    "# size: number of dimension of the embeddings: default is 100 (dimensions as in tokens per vector)\n",
    "# window: the max distance between a target word and words around the target, default is 5\n",
    "# min_count: min count of words to consider when traning the model; words with occurance less than this count will be ignored.\n",
    "        # default is 5\n",
    "# workers: number of partitions during training and default is 3\n",
    "# sg: the traingin algo to use: Either CBOW(0) or skipgram (1)\n",
    "\n",
    "model = Word2Vec(docs, size=16, window=3, min_count=10, workers=3, sg=1)\n",
    "vecs = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13671018,  0.49693862,  0.1728348 ,  0.19943671, -0.21791488,\n",
       "        1.3944778 , -0.33834928, -1.0886257 ,  0.2216287 ,  0.36374584,\n",
       "        0.21042699, -0.41904923,  0.1970994 , -0.75551695,  0.3579834 ,\n",
       "       -0.31583467], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs['bull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90213865"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine similarity: 1 very similar and 0 not similar at all\n",
    "vecs.similarity('biden','trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buy', 0.9362697601318359),\n",
       " ('like', 0.9204457998275757),\n",
       " ('bet', 0.9000283479690552),\n",
       " ('upgrade', 0.8943588733673096),\n",
       " ('bought', 0.8809952735900879),\n",
       " ('rivals', 0.8772242069244385),\n",
       " ('selling', 0.8758612871170044),\n",
       " ('risky', 0.8747047185897827),\n",
       " ('expensive', 0.8741658926010132),\n",
       " ('bonds', 0.8724066019058228)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most similar word\n",
    "vecs.most_similar('sell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a moel\n",
    "# model.save(\"word2vec.model\")\n",
    "\n",
    "# load model\n",
    "# model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vecs.tsv','w') as tsv:\n",
    "    words = model.wv.vocab.keys()\n",
    "\n",
    "    for word in words:\n",
    "        vector = [str(n) for n in model.wv[word]]\n",
    "        row = '\\t'.join(vector) + '\\n'\n",
    "        tsv.write(row)\n",
    "        \n",
    "with open('words.tsv','w') as tsv:\n",
    "    \n",
    "    words = model.wv.vocab.keys()\n",
    "    tsv.write(\"word\" + '\\n')\n",
    "    for word in words:\n",
    "        tsv.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
